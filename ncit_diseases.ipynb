{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import ncit_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the Thesaurus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest NCIt FLAT (tsv) export\n",
    "ncit = ncit_utils.load_ncit()\n",
    "ncit = ncit.set_index(\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Node mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_CACHE: dict[str, \"Node\"] = {}\n",
    "\n",
    "\n",
    "def get_row(code) -> pd.Series:\n",
    "    global ncit\n",
    "    return ncit.loc[code]\n",
    "\n",
    "\n",
    "class Node:\n",
    "    code: str\n",
    "    parents: list[\"Node\"]\n",
    "    synonyms: set[str]\n",
    "    pref_name: str\n",
    "\n",
    "    def __init__(self, row: pd.Series) -> None:\n",
    "        self.code = row.name\n",
    "        self.parents = []\n",
    "        if pd.notna(row[\"parents\"]):\n",
    "            for parent_code in row[\"parents\"].split(\"|\"):\n",
    "                if parent_code not in NODES_CACHE:\n",
    "                    NODES_CACHE[parent_code] = Node(get_row(parent_code))\n",
    "                self.parents.append(NODES_CACHE[parent_code])\n",
    "        self.synonyms = set()\n",
    "        for synonym in row[\"synonyms\"].split(\"|\"):\n",
    "            self.synonyms.add(synonym)\n",
    "        self.pref_name = row[\"display name\"]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"<{self.code} <= {','.join(p.code for p in self.parents)}>\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"<{self.code} <= {','.join(p.code for p in self.parents)}>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_parent_code, row in ncit.iterrows():\n",
    "    node = Node(row)\n",
    "    if r_parent_code not in NODES_CACHE:\n",
    "        NODES_CACHE[r_parent_code] = node\n",
    "print(len(NODES_CACHE))\n",
    "# Test a random code\n",
    "print(NODES_CACHE[\"C142799\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traverse the Node mapping for a certain concept and children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "\n",
    "def get_children_of_code(nodes: dict[str, Node], parent_code: str):\n",
    "    children = set()\n",
    "    for c, n in nodes.items():\n",
    "        if parent_code in [p.code for p in n.parents]:\n",
    "            children.add(c)\n",
    "    return children\n",
    "\n",
    "\n",
    "def bfs(nodes: dict[str, Node], start_code: str):\n",
    "    visited = []  # Keep track of visited nodes.\n",
    "    queue = deque([start_code])  # Queue initialized with the start node code.\n",
    "    tracking_q = deque([(start_code, None)])\n",
    "\n",
    "    while queue:\n",
    "        current_code = queue.popleft()  # Dequeue a node code.\n",
    "        if current_code not in visited:\n",
    "            visited.append(current_code)\n",
    "\n",
    "            # Add all unvisited children to the queue.\n",
    "            if current_code == \"C2991\":\n",
    "                node_children = [\"C3262\"]\n",
    "            else:\n",
    "                node_children = get_children_of_code(nodes, current_code)\n",
    "            for child_code in node_children:\n",
    "                if child_code not in visited:\n",
    "                    queue.append(child_code)\n",
    "                if (child_code, current_code) not in tracking_q:\n",
    "                    tracking_q.append((child_code, current_code))\n",
    "\n",
    "    return visited, tracking_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_concept = \"C2991\"  # disease, disorder, finding\n",
    "# root_concept = \"C3262\"  # neoplasm\n",
    "children, children_w_parents = bfs(NODES_CACHE, root_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the set of child2parents contains all unique pairs\n",
    "combos = set()\n",
    "for tup in children_w_parents:\n",
    "    combos.add(tup)\n",
    "assert len(combos) == len(children_w_parents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for idx, (child, parent) in enumerate(children_w_parents):\n",
    "    if not parent:\n",
    "        assert child == root_concept\n",
    "        continue\n",
    "    child, parent = NODES_CACHE[child], NODES_CACHE.get(parent, None)\n",
    "    for syn in child.synonyms:\n",
    "        data.append(\n",
    "            (\n",
    "                idx + 1,\n",
    "                syn,\n",
    "                child.pref_name,\n",
    "                child.code,\n",
    "                parent.pref_name if parent else None,\n",
    "                parent.code if parent else None,\n",
    "            )\n",
    "        )\n",
    "output = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"Level\",\n",
    "        \"Term\",\n",
    "        \"Preferred Term\",\n",
    "        \"Code\",\n",
    "        \"Parent Term\",\n",
    "        \"Parent Term Code\",\n",
    "    ],\n",
    "    dtype=str,\n",
    ")\n",
    "output.to_csv(\"disease_codes.csv\", index=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call EVS API to get preferred terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_terms_df = ncit_utils.EVSConceptsApi.load_terms_w_synonyms(\n",
    "    children, \"ncit_output/preferred_terms_diseases.csv\"\n",
    ")\n",
    "disease_terms_df = disease_terms_df.dropna(subset=['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply EVS terms to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "syn_to_sources = defaultdict(set)\n",
    "\n",
    "for _, row in disease_terms_df.iterrows():\n",
    "    r_code = row[\"code\"]\n",
    "    syn = row[\"synonym\"]\n",
    "    source = row[\"source\"]\n",
    "    syn_to_sources[(r_code, syn)].add(source)\n",
    "\n",
    "\n",
    "def get_sources(row: pd.Series):\n",
    "    as_list = list(syn_to_sources[(row[\"Code\"], row[\"Term\"])])\n",
    "    as_list.sort()\n",
    "    return \",\".join(as_list)\n",
    "\n",
    "\n",
    "output[\"Sources\"] = output[[\"Term\", \"Code\"]].apply(get_sources, axis=1)\n",
    "assert not output[\"Sources\"].isna().any()\n",
    "display(output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use existing pref term if provided by NCIt\n",
    "# Else use the EVS preferred name\n",
    "code_to_term_map = {}\n",
    "\n",
    "\n",
    "def code_to_term(code: str):\n",
    "    if code not in code_to_term_map:\n",
    "        term = disease_terms_df.loc[disease_terms_df[\"code\"] == code, \"name\"].iloc[0]\n",
    "        code_to_term_map[code] = term\n",
    "    return code_to_term_map[code]\n",
    "\n",
    "\n",
    "output[\"Preferred Term\"] = output.apply(\n",
    "    lambda row: row[\"Preferred Term\"]\n",
    "    if not pd.isna(row[\"Preferred Term\"])\n",
    "    else code_to_term(row[\"Code\"]),\n",
    "    axis=1,\n",
    ")\n",
    "print(\"Done with Preferred Term.\")\n",
    "output[\"Parent Term\"] = output.apply(\n",
    "    lambda row: row[\"Parent Term\"]\n",
    "    if not pd.isna(row[\"Parent Term\"])\n",
    "    else code_to_term(row[\"Parent Term Code\"]),\n",
    "    axis=1,\n",
    ")\n",
    "assert output[\"Preferred Term\"].hasnans is False\n",
    "assert output[\"Parent Term\"].hasnans is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not output.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term2code = output.loc[:, [\"Term\", \"Code\"]].drop_duplicates()\n",
    "term2code = term2code.sort_values(by=[\"Term\"])\n",
    "term2code.to_csv(\"disease_syn_2_code.tsv\", sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "code2pref_term = output.loc[:, [\"Code\", \"Preferred Term\"]].drop_duplicates()\n",
    "code2pref_term = code2pref_term.sort_values(by=[\"Code\"])\n",
    "code2pref_term.to_csv(\n",
    "    \"disease_code_2_pref_term.tsv\", sep=\"\\t\", index=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "output.to_csv(\"disease_ncit_concepts.tsv\", sep=\"\\t\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_checked = set()\n",
    "\n",
    "\n",
    "def check_output(row: pd.Series):\n",
    "    r_code = row[\"Code\"]\n",
    "    r_parent_code = row[\"Parent Term Code\"]\n",
    "    if r_parent_code in parents_checked:\n",
    "        return\n",
    "\n",
    "    parents_checked.add(r_parent_code)\n",
    "\n",
    "    if r_parent_code != \"C2991\":\n",
    "        assert (\n",
    "            pd.Series(r_parent_code).isin(output[\"Code\"]).any()\n",
    "        ), f\"Failed to find {r_parent_code} in output Codes\"\n",
    "\n",
    "    assert r_code in children, \"Every code should have been visited\"\n",
    "\n",
    "    parent_terms: pd.Series = output[\"Parent Term\"].loc[\n",
    "        output[\"Parent Term Code\"] == r_parent_code\n",
    "    ]\n",
    "    assert (\n",
    "        len(parent_terms.unique()) == 1\n",
    "    ), f\"Parent Code {r_parent_code} should have the same Parent Term {parent_terms}\"\n",
    "\n",
    "    terms: pd.Series = output[\"Preferred Term\"].loc[output[\"Code\"] == r_code]\n",
    "    assert (\n",
    "        len(terms.unique()) == 1\n",
    "    ), f\"Code {r_code} should have the same Preferred Term {terms}\"\n",
    "\n",
    "\n",
    "_ = output.apply(check_output, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
