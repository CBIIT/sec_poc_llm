{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34dddb4-6838-45ad-a805-2836af7ff6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434fa8e-0ebb-4b60-aa18-d305531a0ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    # stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    max_new_tokens=256,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1,  # without this output begins repeating\n",
    "    do_sample=True,\n",
    "    # streamer = transformers.TextStreamer(tokenizer)\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14e5e4-8aa0-4140-9b5e-7cf26677dffd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from prompt_examples.single_criterion_examples import prompt, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c99a8-f29f-44e0-a738-2977f72ec7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(prompt.format(criterion=\"\"\"Patient must have undergone complete surgical resection of their stage IIA, IIB, IIIA or IIIB non-squamous or squamous b NSCLC per American Joint Committee on Cancer (AJCC) 8th edition and have had negative margins. N3 disease is not allowed.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ef896-2a6a-4cf3-acdc-6b036b01a36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from token_counting import *\n",
    "globalize_token_metrics(examples)\n",
    "print('  avg prompt:', AVG_PROMPT_LEN)\n",
    "print('  min prompt:', MIN_PROMPT_LEN)\n",
    "print('  max prompt:', MAX_PROMPT_LEN)\n",
    "print('avg response:', AVG_RES_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02c6e5-e477-47be-a50c-5509444e292c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chunking import parse_file_with_pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78706696-5748-4432-a898-82f9140f55d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "import time\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from langchain.chains import LLMChain\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "\n",
    "langchain.debug = False\n",
    "langchain.verbose = False\n",
    "\n",
    "n = '10'\n",
    "folder = f'test_results_final/trial{n}'\n",
    "folderp = Path(folder)\n",
    "logfile = folderp / \"outputs.log\"\n",
    "# logfile = folderp / \"outputs_amended.log\"\n",
    "logger.add(logfile, colorize=False, enqueue=True)\n",
    "handler = langchain.callbacks.FileCallbackHandler(logfile)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler], verbose=False)\n",
    "\n",
    "criterions = parse_file_with_pipes(folderp / 'ec_with_pipes.txt')\n",
    "start = time.time()\n",
    "invoke_times = []\n",
    "for idx, criterion in enumerate(tqdm(criterions, file=sys.stdout)):\n",
    "    idx += 1\n",
    "    # if idx != 3:\n",
    "    #     continue\n",
    "    invoke_start = time.time()\n",
    "    results = llm_chain.invoke(input={'criterion': criterion.value})\n",
    "    invoke_times.append(time.time() - invoke_start)\n",
    "    with open(folderp / f'{idx:02}_output.txt', 'w', encoding='utf-8') as fileout:\n",
    "        fileout.write(results['text'])\n",
    "    with open(folderp / f'{idx:02}_stats.yaml', 'w', encoding='utf-8') as fileout:\n",
    "        fileout.write(f\"\"\"elapsed_time: {int(time.time() - invoke_start)}s\n",
    "was_input_captured: {criterion.value in results['text']}\n",
    "original_text: |\n",
    "    {criterion.value}\n",
    "inclusion: {criterion.inclusion}\n",
    "\"\"\")\n",
    "    # if idx == 3:\n",
    "    #     break\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de873179-5723-4bd1-8aa3-256f827e90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folderp / 'stats.yaml', 'w', encoding='utf-8') as fileout:\n",
    "    fileout.write(f\"\"\"total_time: {(end - start) // 60}min\n",
    "avg_invoke_time: {sum(invoke_times) // len(invoke_times)}s\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e954e-60a2-472b-a038-c1b58f040280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import glob\n",
    "\n",
    "stats_files = glob.glob(str(folderp / '*_stats.yaml'))\n",
    "stats_files.sort()\n",
    "for idx, file in enumerate(stats_files):\n",
    "    idx += 1\n",
    "    with open(file, encoding='utf-8') as filein:\n",
    "        try:\n",
    "            stats = yaml.safe_load(filein)\n",
    "        except Exception as e:\n",
    "            print(file)\n",
    "            raise e\n",
    "    if not stats['was_input_captured']:\n",
    "        print(f'Input failed {idx:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635e145-9067-4828-a286-3c5a93ef8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing\n",
    "output_files = glob.glob(str(folderp / '*_output.txt'))\n",
    "output_files.sort()\n",
    "for idx, file in enumerate(output_files):\n",
    "    idx += 1\n",
    "    stop_word = 'Criterion:'\n",
    "    lines = []\n",
    "    with open(file, encoding='utf-8') as filein:\n",
    "        original_text = False\n",
    "        for line in filein:\n",
    "            if line.startswith(stop_word):\n",
    "                break\n",
    "            if line == '\\n':\n",
    "                continue\n",
    "            if 'Original Text:' in line:\n",
    "                original_text = True\n",
    "                key = 'Original Text'\n",
    "                _, original_text_l1 = line.split(': ', maxsplit=1)\n",
    "                lines.append(key + ': |\\n')\n",
    "                lines.append('    ' + original_text_l1)\n",
    "            elif 'Disease/Condition:' in line:\n",
    "                original_text = False\n",
    "                lines.append(line.removeprefix('\\t').removeprefix('    '))\n",
    "            elif original_text:\n",
    "                lines.append('    ' + line)\n",
    "            elif 'Computable Rule:' in line:\n",
    "                key = 'Computable Rule'\n",
    "                _, computable_rule = line.split(': ', maxsplit=1)\n",
    "                lines.append(key + ': |\\n')\n",
    "                lines.append('    ' + computable_rule)\n",
    "            else:\n",
    "                lines.append(line.removeprefix('\\t').removeprefix('    '))\n",
    "    output_reassembled = ''.join(lines)\n",
    "    if 'Computable Rule' not in output_reassembled:\n",
    "        print('Malformed output:', idx)\n",
    "    with open(folderp / f'{idx:02}_output_cleaned.yaml', 'w', encoding='utf-8') as fileout:\n",
    "        fileout.write(output_reassembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e182cd8-b520-4ca4-8c8a-225efcaf9f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_files_clean = glob.glob(str(folderp / '*_output_cleaned.yaml'))\n",
    "output_files_clean.sort()\n",
    "df = pd.DataFrame(columns=['Criterion Text In', 'Criterion Text Out', 'Inclusion/Exclusion', 'Disease', 'Biomarker', 'Procedure', 'Drug', 'Criterion Rule'])\n",
    "for idx, file in enumerate(output_files_clean):\n",
    "    idx += 1\n",
    "    with open(folderp / f'{idx:02}_stats.yaml', encoding='utf-8') as filein:\n",
    "        stats = yaml.safe_load(filein)\n",
    "    with open(file, encoding='utf-8') as filein:\n",
    "        print(file)\n",
    "        output = yaml.safe_load(filein)\n",
    "    # if idx in (20,):\n",
    "    #     output['Disease/Condition'] = None\n",
    "    #     output['Biomarker'] = None\n",
    "    #     output['Procedure'] = None\n",
    "    #     output['Drug'] = None\n",
    "    #     output['Computable Rule'] = None\n",
    "    row = {\n",
    "        'Criterion Text In': stats['original_text'],\n",
    "        'Criterion Text Out': output['Original Text'].strip(),\n",
    "        'Inclusion/Exclusion': 'Inclusion' if stats['inclusion'] else 'Exclusion',\n",
    "        'Disease': output['Disease/Condition'],\n",
    "        'Biomarker': output['Biomarker'],\n",
    "        'Procedure': output['Procedure'],\n",
    "        'Drug': output['Drug'],\n",
    "        'Criterion Rule': output['Computable Rule']\n",
    "    }\n",
    "    df = df.append(row, ignore_index=True)\n",
    "df = df.replace('none', None).replace('None', None)\n",
    "df.to_csv(folderp / 'results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d722dd-e46b-401f-b8da-294556004acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flag_files = glob.glob(str(folderp / '*_flag.txt'))\n",
    "flag_files.sort()\n",
    "for file in flag_files:\n",
    "    with open(file, encoding='utf-8') as filein:\n",
    "        flags = filein.read()\n",
    "    print(f'==== {file} ====')\n",
    "    print(flags, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
