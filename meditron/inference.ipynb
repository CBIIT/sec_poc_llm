{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38e1558-1a7a-4997-913e-31d19f0f3e79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token=\"\"\n",
    "model_id=\"epfl-llm/meditron-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c5e595-f7a3-4047-8294-0831cc48a1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d11dffdac9445368954ac0013bf14eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_id,token=token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, token=token, load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dab2cd-3c82-4968-84f3-36d0a2f83677",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5e9a0-f78f-4196-a05d-cc72f00ede05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c7d1b8-dc4b-49dd-bad4-eb914d9cbea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "stop_list = [\"\\n12\", \"\\n12:\", \"\\n12:\", \"\\n12:   Sentence:\"]\n",
    "stop_token_ids = [tokenizer(x, add_special_tokens=False)['input_ids'] for x in stop_list]\n",
    "stop_token_ids = [torch.LongTensor(x).to('cuda') for x in stop_token_ids]\n",
    "\n",
    "# define custom stopping criteria object\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        # print(input_ids[0][-3:])\n",
    "        for stop_ids in stop_token_ids:\n",
    "            # decoded = tokenizer.decode(input_ids[0][-3])\n",
    "            if torch.eq(input_ids[0][-3:], torch.tensor([29896, 29906, 29901]).to('cuda')).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])\n",
    "\n",
    "settings = {\n",
    "    'max_new_tokens': 256,\n",
    "    # 'temperature': 0.6,\n",
    "    # 'top_p': 0.5,\n",
    "    # 'top_k': 35,\n",
    "    # 'do_sample': True,\n",
    "    # 'repetition_penalty': 1.1,\n",
    "    'penalty_alpha': 0.5,\n",
    "    'top_k': 4,\n",
    "    'pad_token_id': tokenizer.eos_token_id,\n",
    "    # 'stopping_criteria': stopping_criteria,\n",
    "    # 'return_dict_in_generate': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3907df97-0e93-40bd-b228-53cc37a365b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[tensor([29871,    13, 29896, 29906], device='cuda:0'), tensor([29871,    13, 29896, 29906, 29901], device='cuda:0'), tensor([29871,    13, 29896, 29906, 29901], device='cuda:0'), tensor([29871,    13, 29896, 29906, 29901,   259, 28048,   663, 29901],\n",
      "       device='cuda:0')]\n",
      "['\\n12', '\\n12:', '\\n12:', '\\n12:   Sentence:']\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_token_ids[0]))\n",
    "print(stop_token_ids)\n",
    "print(tokenizer.batch_decode(stop_token_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd997b4-e283-48b1-98d0-dc6177113ed9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea186b25-9a00-4c7c-a6fc-bc2d1fddfd72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "import gc\n",
    "\n",
    "def do_generate(prompt: str, use_stream=True):\n",
    "    new_streamer = TextStreamer(tokenizer) if use_stream else None\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    len_inputs = len(inputs['input_ids'][0])\n",
    "    print(' len(input): ', len_inputs)\n",
    "    outputs = model.generate(**inputs, **settings)\n",
    "    print('len(output): ', len(outputs[0]) - len_inputs)\n",
    "    print(' len(total): ', len(outputs[0]))\n",
    "    # gen_text = tokenizer.batch_decode(outputs[0][len_inputs:])\n",
    "    gc.collect()\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ddc3f-ebd6-422e-9d37-af75879fec96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(do_generate(\"\"\"\n",
    "0:    Sentence:      Signed informed consent must be obtained prior to performing any specific pre-screening and screening procedure.\n",
    "1:    biomarkers:    none\n",
    "2:    Sentence:      Male or female >= 18 years of age at the time of informed consent\n",
    "3:    biomarkers:    none\n",
    "4:    Sentence:      Histologically or cytologically confirmed diagnosis of advanced/metastatic differentiated thyroid cancer\n",
    "5:    biomarkers:    none\n",
    "6:    Sentence:      BRAFV600E mutation positive tumor sample as per Novartis designated central laboratory result\n",
    "7:    biomarkers:    BRAFV600E\n",
    "8:    Sentence:      Concomitant RET Fusion Positive Thyroid cancer\n",
    "9:    biomarkers:    RET Fusion Positive\n",
    "10:   Sentence:      Estrogen receptor (ER)+/HER2-, defined as > 5% ER+ staining\n",
    "11:   biomarkers:    \"\"\", use_stream=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1939f16-22a5-47a6-9c94-56acf4b50e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.batch_decode([[29896, 29906, 29901],[29906, 29901,   259]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b757f36-3386-4d8f-ba42-e17ab9bbd307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_prompt = \"\"\"\n",
    "0:    Sentence:      Signed informed consent must be obtained prior to performing any specific pre-screening and screening procedure.\n",
    "1:    biomarkers:    none\n",
    "2:    Sentence:      Male or female >= 18 years of age at the time of informed consent\n",
    "3:    biomarkers:    none\n",
    "4:    Sentence:      Histologically or cytologically confirmed diagnosis of advanced/metastatic differentiated thyroid cancer\n",
    "5:    biomarkers:    none\n",
    "6:    Sentence:      BRAFV600E mutation positive tumor sample as per Novartis designated central laboratory result\n",
    "7:    biomarkers:    BRAFV600E\n",
    "8:    Sentence:      Concomitant RET Fusion Positive Thyroid cancer\n",
    "9:    biomarkers:    RET Fusion Positive\n",
    "10:   Sentence:      {sentence}\n",
    "11:   biomarkers:    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
