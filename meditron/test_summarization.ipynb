{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04049c68-2e40-4a8b-9cf8-0810c2264b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1021d0e2-364a-4abf-a3ef-02a75d4b949c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6e82145d214dd883fc47b7ab942aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import transformers\n",
    "\n",
    "model_id=\"epfl-llm/meditron-7b\"\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# set quantization configuration to load large model with less GPU memory\n",
    "# this requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    # token=token\n",
    ")\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    # token=token\n",
    ")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    # token=token\n",
    ")\n",
    "\n",
    "# enable evaluation mode to allow model inference\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80efc1b6-8e3f-4f5f-b17f-65c8b0eceed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_token_len(text: str):\n",
    "    return len(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba54b270-f43c-4917-bad2-519aa4ab9f75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([29871,    13,    13], device='cuda:0'), tensor([29871,    13,    13,    13], device='cuda:0'), tensor([ 9330, 29901,    13, 21140,   340], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "\n",
    "stop_list = [\"\\n\\n\", \"\\n\\n\\n\", \"Task:\\nBelow\"]\n",
    "# stop_list = ['\\nHuman:', '\\n```\\n']\n",
    "stop_token_ids = [tokenizer(x, add_special_tokens=False)['input_ids'] for x in stop_list]\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
    "print(stop_token_ids)\n",
    "\n",
    "# define custom stopping criteria object\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3167ac-85da-4355-b0a0-89cff695084d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    max_new_tokens=256,  # max number of tokens to generate in the output\n",
    "    repetition_penalty=1.1,  # without this output begins repeating\n",
    "    do_sample=True,\n",
    "    streamer = transformers.TextStreamer(tokenizer)\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640268cf-85a8-4f50-aaf0-4ea9110a073d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prompt_examples.summarization_examples import prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd50165-114c-44ab-b1c0-9ce6a6cd7581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:\n",
      "Below is an example of ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Task:\n",
      "Below is an example of clinical trial eligibility inclusion/exclusion criteria. Your task is to identify 3 categories of data within it. The 3 categories are: 1) Disease: a disorder affecting humans, 2) Biomarker: genes, proteins, or other substances that can be tested for to reveal important details about a patient’s cancer, and 3) Prior Therapy: medications, surgeries, or procedures that a patient may be treated with. For each of the identified categories, state whether it is an inclusion or exclusion.\n",
      "Criteria:\n",
      "    \n",
      "Inclusion Criteria\n",
      "•\tCOHORT A: At least one measurable CNS metastasis, defined as >= 10 mm in at least one dimension\n",
      "•\tCOHORT A: Unequivocal evidence of new and/or progressive brain metastases, and at least one of the following scenarios:\n",
      "•\tTreated with stereotactic radiosurgery (SRS) or surgery with residual un-treated lesions remaining. Such participants are eligible for immediate enrollment on this study providing that at least one untreated lesion is measurable\n",
      "•\tParticipants who have had prior whole brain radiotherapy (WBRT) and/or SRS and then whose lesions have subsequently progressed or who have new lesions are also eligible. In this case, lesions which have been treated with SRS may be considered as target lesions if there is unequivocal evidence, in the opinion of the treating physician, of progression following SRS\n",
      "•\tParticipants who have not previously been treated with cranial radiation (e.g., WBRT or SRS) are eligible to enter the study, but such participants must be asymptomatic from their CNS metastases and not requiring corticosteroids for symptom control\n",
      "•\tParticipants who present with systemic stable/absent or progressive disease are eligible to this trial, as long as they fulfill one of the above criteria\n",
      "•\tCOHORT B: New and/or progressive brain metastasis(es) with clinical indication for resection\n",
      "•\tPathologically confirmed HER2-positive MBC by local laboratory with the following requirements: HER2 overexpressed or amplified (immunohistochemistry of 3+ or HER2 gene amplification by in situ hybridization with a ratio of HER2-gene signals to centromere 17 signals >= 2.0 or average HER2 copy number >= 6.0 signals/cells)\n",
      "•\tEastern Cooperative Oncology Group (ECOG) performance status of =< 2\n",
      "•\tLeft ventricular ejection fraction (LVEF) >= 50% by echocardiogram (ECHO) or multigated acquisition (MUGA) scan\n",
      "\n",
      "Exclusion Criteria\n",
      "•\tVisceral crisis or impending visceral crisis at time of screening\n",
      "•\tCNS complications for whom urgent neurosurgical intervention is indicated (e.g., resection, shunt placement)\n",
      "•\tKnown leptomeningeal metastases (defined as positive CSF cytology and/or unequivocal radiological evidence of clinically significant leptomeningeal involvement. CSF sampling is not required in the absence of suggestive symptoms to exclude leptomeningeal involvement)\n",
      "•\tPatients with known contraindication to magnetic resonance imaging (MRI) (e.g., due to pacemaker, ferromagnetic implants, claustrophobia, extreme obesity, hypersensitivity, etc.). However, head computed tomography (CT) with contrast may be used in place of MRI at baseline and throughout the trial if MRI is contraindicated and a participant’s brain metastases are clearly measurable by head CT\n",
      "•\tChemotherapy or targeted therapy within 14 days prior to initiation of protocol therapy. No washout is required for trastuzumab\n",
      "•\tHas received prior therapy with a PI3K or mTOR inhibitor\n",
      "•\tNo washout is required for endocrine therapy. If a patient has been on ovarian suppression for at least 28 days prior to initiation of study treatment, continuation of ovarian suppression is permitted on protocol. Starting a new endocrine therapy during protocol therapy is not permitted\n",
      "•\tCurrent use or history of receiving a non-approved, investigational treatment within 14 days prior to initiation of protocol therapy\n",
      "•\tSubjects with a history of hypersensitivity to compounds of similar biologic composition to paxalisib (GDC-0084) or any constituent of the product\n",
      "•\tThe subject has an uncontrolled intercurrent illness, including, but not limited to, ongoing or active infection, uncontrolled hypertension, unstable angina pectoris, uncontrolled cardiac arrhythmia, congestive heart failure-New York Heart Association class III or IV, active ischemic heart disease, myocardial infarction within the previous six months, uncontrolled diabetes mellitus (DM), gastric or duodenal ulceration diagnosed within the previous 6 months, chronic liver or renal disease, or severe malnutrition. If a participant has controlled DM but is unable to monitor blood sugars at home, they will be excluded from the trial\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(criteria=\"\"\"\n",
    "Inclusion Criteria\n",
    "•\tCOHORT A: At least one measurable CNS metastasis, defined as >= 10 mm in at least one dimension\n",
    "•\tCOHORT A: Unequivocal evidence of new and/or progressive brain metastases, and at least one of the following scenarios:\n",
    "•\tTreated with stereotactic radiosurgery (SRS) or surgery with residual un-treated lesions remaining. Such participants are eligible for immediate enrollment on this study providing that at least one untreated lesion is measurable\n",
    "•\tParticipants who have had prior whole brain radiotherapy (WBRT) and/or SRS and then whose lesions have subsequently progressed or who have new lesions are also eligible. In this case, lesions which have been treated with SRS may be considered as target lesions if there is unequivocal evidence, in the opinion of the treating physician, of progression following SRS\n",
    "•\tParticipants who have not previously been treated with cranial radiation (e.g., WBRT or SRS) are eligible to enter the study, but such participants must be asymptomatic from their CNS metastases and not requiring corticosteroids for symptom control\n",
    "•\tParticipants who present with systemic stable/absent or progressive disease are eligible to this trial, as long as they fulfill one of the above criteria\n",
    "•\tCOHORT B: New and/or progressive brain metastasis(es) with clinical indication for resection\n",
    "•\tPathologically confirmed HER2-positive MBC by local laboratory with the following requirements: HER2 overexpressed or amplified (immunohistochemistry of 3+ or HER2 gene amplification by in situ hybridization with a ratio of HER2-gene signals to centromere 17 signals >= 2.0 or average HER2 copy number >= 6.0 signals/cells)\n",
    "•\tEastern Cooperative Oncology Group (ECOG) performance status of =< 2\n",
    "•\tLeft ventricular ejection fraction (LVEF) >= 50% by echocardiogram (ECHO) or multigated acquisition (MUGA) scan\n",
    "\n",
    "Exclusion Criteria\n",
    "•\tVisceral crisis or impending visceral crisis at time of screening\n",
    "•\tCNS complications for whom urgent neurosurgical intervention is indicated (e.g., resection, shunt placement)\n",
    "•\tKnown leptomeningeal metastases (defined as positive CSF cytology and/or unequivocal radiological evidence of clinically significant leptomeningeal involvement. CSF sampling is not required in the absence of suggestive symptoms to exclude leptomeningeal involvement)\n",
    "•\tPatients with known contraindication to magnetic resonance imaging (MRI) (e.g., due to pacemaker, ferromagnetic implants, claustrophobia, extreme obesity, hypersensitivity, etc.). However, head computed tomography (CT) with contrast may be used in place of MRI at baseline and throughout the trial if MRI is contraindicated and a participant’s brain metastases are clearly measurable by head CT\n",
    "•\tChemotherapy or targeted therapy within 14 days prior to initiation of protocol therapy. No washout is required for trastuzumab\n",
    "•\tHas received prior therapy with a PI3K or mTOR inhibitor\n",
    "•\tNo washout is required for endocrine therapy. If a patient has been on ovarian suppression for at least 28 days prior to initiation of study treatment, continuation of ovarian suppression is permitted on protocol. Starting a new endocrine therapy during protocol therapy is not permitted\n",
    "•\tCurrent use or history of receiving a non-approved, investigational treatment within 14 days prior to initiation of protocol therapy\n",
    "•\tSubjects with a history of hypersensitivity to compounds of similar biologic composition to paxalisib (GDC-0084) or any constituent of the product\n",
    "•\tThe subject has an uncontrolled intercurrent illness, including, but not limited to, ongoing or active infection, uncontrolled hypertension, unstable angina pectoris, uncontrolled cardiac arrhythmia, congestive heart failure-New York Heart Association class III or IV, active ischemic heart disease, myocardial infarction within the previous six months, uncontrolled diabetes mellitus (DM), gastric or duodenal ulceration diagnosed within the previous 6 months, chronic liver or renal disease, or severe malnutrition. If a participant has controlled DM but is unable to monitor blood sugars at home, they will be excluded from the trial\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e53318-366a-4037-a594-371a80d2f86b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f23e97-3728-4061-bb95-6b0b6842b3de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         avg: 594\n",
      "         min: 491\n",
      "         max: 704\n",
      "avg response: 72\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "total_res = 0\n",
    "minm = 2000\n",
    "maxm = 0\n",
    "for example in examples:\n",
    "    context_len = get_token_len(example['context'])\n",
    "    answer_len = get_token_len(example['answer'])\n",
    "    combined_len = context_len + answer_len\n",
    "    if combined_len < minm:\n",
    "        minm = combined_len\n",
    "    elif combined_len > maxm:\n",
    "        maxm = combined_len\n",
    "    total += combined_len\n",
    "    total_res += answer_len\n",
    "AVG_EXAMPLE_LEN = total // len(examples)\n",
    "MAX_W_SIZE = 2048\n",
    "AVG_RES_LEN = total_res // len(examples)\n",
    "print('         avg:', AVG_EXAMPLE_LEN)\n",
    "print('         min:', minm)\n",
    "print('         max:', maxm)\n",
    "print('avg response:', AVG_RES_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d423e3b-69ce-44cb-b451-b2aee94db13a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ECDoc:\n",
    "    inc: list[str]\n",
    "    exc: list[str]\n",
    "    template = \"\"\"Inclusion Criteria\n",
    "{inclusion}\n",
    "\n",
    "Exclusion Criteria\n",
    "{exclusion}\n",
    "\"\"\"\n",
    "    \n",
    "    def __init__(self, inc: list[str], exc: list[str]):\n",
    "        self.inc = inc\n",
    "        self.exc = exc\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return get_token_len(str(self))\n",
    "\n",
    "    def __str__(self) -> list[str]:\n",
    "        return self.template.format(inclusion=''.join(self.inc).rstrip(),\n",
    "                                   exclusion=''.join(self.exc).rstrip())\n",
    "\n",
    "    def split(self):\n",
    "        inc_len = len(self.inc)\n",
    "        exc_len = len(self.exc)\n",
    "        inc_midpoint = inc_len // 2\n",
    "        exc_midpoint = exc_len // 2\n",
    "        # Prevent Inclusion section from splitting too small\n",
    "        if inc_len <= 5:\n",
    "            inc_chunk_1 = self.inc\n",
    "            inc_chunk_2 = self.inc\n",
    "        else:\n",
    "            inc_chunk_1 = self.inc[:inc_midpoint]\n",
    "            inc_chunk_2 = self.inc[inc_midpoint:]\n",
    "        # Prevent Exclusion section from splitting too small\n",
    "        if exc_len <= 5:\n",
    "            exc_chunk_1 = self.exc\n",
    "            exc_chunk_2 = self.exc\n",
    "        else:\n",
    "            exc_chunk_1 = self.exc[:exc_midpoint]\n",
    "            exc_chunk_2 = self.exc[exc_midpoint:]\n",
    "        doc_chunk_1 = ECDoc(inc=inc_chunk_1, exc=exc_chunk_1)\n",
    "        doc_chunk_2 = ECDoc(inc=inc_chunk_2, exc=exc_chunk_2)\n",
    "        return doc_chunk_1, doc_chunk_2\n",
    "\n",
    "\n",
    "def parse_file(filename: str) -> ECDoc:\n",
    "    inc = []\n",
    "    exc = []\n",
    "    inclusion = True\n",
    "    with open(filename) as filein:\n",
    "        for line in filein.readlines():\n",
    "            if line.strip().startswith('Inclusion Criteria'):\n",
    "                continue\n",
    "            elif line.strip().startswith('Exclusion Criteria'):\n",
    "                inclusion = False\n",
    "                continue\n",
    "            elif line == '\\n':\n",
    "                continue\n",
    "            if inclusion:\n",
    "                inc.append(line)\n",
    "            else:\n",
    "                exc.append(line)\n",
    "    return ECDoc(inc=inc, exc=exc)\n",
    "\n",
    "\n",
    "def chunk_ec(doc: ECDoc) -> list[ECDoc]:\n",
    "    # Not too large\n",
    "    can_fit = doc.size + AVG_EXAMPLE_LEN < MAX_W_SIZE - AVG_RES_LEN\n",
    "    if can_fit:\n",
    "        return [doc]\n",
    "   \n",
    "    last_pass_chunks = [doc]\n",
    "    while not can_fit:\n",
    "        new_chunks = []\n",
    "        for chunk in last_pass_chunks:\n",
    "            new_chunks.extend(chunk.split())\n",
    "        new_chunk_size = max([new_chunk.size for new_chunk in new_chunks])\n",
    "        can_fit = new_chunk_size + AVG_EXAMPLE_LEN < MAX_W_SIZE - AVG_RES_LEN\n",
    "        last_pass_chunks = new_chunks\n",
    "    return new_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c6b51-e531-4edc-bef9-2f400bf6244b",
   "metadata": {},
   "source": [
    "## Process and test trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca9e975-e69c-4acd-8254-e02a8253357a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f0f21-47d3-4b94-a160-c731a54e7731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trialN = '10'\n",
    "original_doc = parse_file(f'test_results/trial{trialN}/unstructured_ec.txt')\n",
    "doc_chunks = chunk_ec(original_doc)\n",
    "doc_reassembled = ECDoc([], [])\n",
    "for idx, doc in enumerate(doc_chunks):\n",
    "    with open(f'test_results/trial{trialN}/unstructured_ec_chunk{idx}', 'w') as chunkfile:\n",
    "        chunkfile.writelines(str(doc))\n",
    "    output = llm_chain.run(criteria=str(doc))\n",
    "    with open(f'test_results/trial{trialN}/output_chunk{idx}', 'w') as chunkfile:\n",
    "        chunkfile.writelines(output)\n",
    "    doc_reassembled.inc.extend(doc.inc)\n",
    "    doc_reassembled.exc.extend(doc.exc)\n",
    "with open(f'test_results/trial{trialN}/unstructured_ec_reassembled', 'w') as docfile:\n",
    "        docfile.write(str(doc_reassembled).rstrip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
